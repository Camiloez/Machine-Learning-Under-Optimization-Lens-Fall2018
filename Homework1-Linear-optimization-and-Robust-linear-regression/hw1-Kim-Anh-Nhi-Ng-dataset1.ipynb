{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Gurobi, DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mreadtable is deprecated, use CSV.read from the CSV package instead\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1m#readtable#232\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Bool, ::Char, ::Array{Char,1}, ::Char, ::Array{String,1}, ::Array{String,1}, ::Array{String,1}, ::Bool, ::Int64, ::Array{Symbol,1}, ::Array{Any,1}, ::Bool, ::Char, ::Bool, ::Int64, ::Array{Int64,1}, ::Bool, ::Symbol, ::Bool, ::Bool, ::DataFrames.#readtable, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\utilisateur\\.julia\\v0.6\\DataFrames\\src\\deprecated.jl:1045\u001b[22m\u001b[22m\n",
      " [3] \u001b[1m(::DataFrames.#kw##readtable)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::DataFrames.#readtable, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\<missing>:0\u001b[22m\u001b[22m\n",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:522\u001b[22m\u001b[22m\n",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\utilisateur\\.julia\\v0.6\\Compat\\src\\Compat.jl:88\u001b[22m\u001b[22m\n",
      " [6] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\utilisateur\\.julia\\v0.6\\IJulia\\src\\execute_request.jl:180\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::Compat.#inner#14{Array{Any,1},IJulia.#execute_request,Tuple{ZMQ.Socket,IJulia.Msg}})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\utilisateur\\.julia\\v0.6\\Compat\\src\\Compat.jl:332\u001b[22m\u001b[22m\n",
      " [8] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\utilisateur\\.julia\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [9] \u001b[1m(::IJulia.##15#18)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[2], in expression starting on line 1\n"
     ]
    }
   ],
   "source": [
    "df = readtable(\"housing.csv\",header=false)\n",
    "X = Matrix(df[1:end - 1])\n",
    "y = df[end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, validation and test sets (50%/25%/25%)\n",
    "n = length(y)\n",
    "val_start, test_start  = round(Int, 0.50 * n), round(Int, 0.75 * n)\n",
    "\n",
    "train_X, train_y = X[1:val_start - 1, :], y[1:val_start - 1]\n",
    " \n",
    "val_X = X[val_start:test_start - 1, :]\n",
    "val_y = y[val_start:test_start - 1]\n",
    "test_X = X[test_start:end, :]\n",
    "test_y = y[test_start:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:(252, 13)(252,)\n",
      "Size of validation set:(127, 13)(127,)\n",
      "Size of test set:(127, 13)(127,)\n"
     ]
    }
   ],
   "source": [
    "#See the size of training set and test set\n",
    "println(\"Size of training set:\",size(train_X),size(train_y))\n",
    "println(\"Size of validation set:\",size(val_X),size(val_y))\n",
    "println(\"Size of test set:\",size(test_X),size(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ridgelinear (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the training functions for different types of linear regressions\n",
    "\n",
    "##### standard linear regression #####\n",
    "function standardlinear(X, y)\n",
    "    # OutputFlag=0 to hide output from solver\n",
    "    m = Model(solver=GurobiSolver(OutputFlag=0))    \n",
    "    p = size(X, 2) #nb of columns\n",
    "\n",
    "    #variables    \n",
    "    @variable(m, t)\n",
    "    @variable(m, β[1:p])\n",
    "    \n",
    "    # Constraints\n",
    "    @constraint(m, norm(y - X * β) <= t)\n",
    "\n",
    "    # Objective\n",
    "    @objective(m, Min, t)\n",
    "\n",
    "    solve(m)\n",
    "\n",
    "    return getvalue(β)\n",
    "end\n",
    "\n",
    "##### lasso linear regression #####\n",
    "function lassolinear(X, y, ρ)\n",
    "    # OutputFlag=0 to hide output from solver\n",
    "    m = Model(solver=GurobiSolver(OutputFlag=0))\n",
    "    p = size(X, 2) #nb of columns\n",
    "    \n",
    "    #variables    \n",
    "    @variable(m, t)\n",
    "    @variable(m, β[1:p])\n",
    "    @variable(m, a[1:p])\n",
    "    \n",
    "    # Constraints\n",
    "    @constraint(m, norm(y - X * β) <= t)\n",
    "    @constraint(m, -a[1:p] .<= β[1:p])\n",
    "    @constraint(m, β[1:p] .<= a[1:p])\n",
    "    @constraint(m, a[1:p] .>= 0)\n",
    "    \n",
    "    # Objective\n",
    "    @objective(m, Min, t + ρ * sum(a[j] for j = 1:p))\n",
    "\n",
    "    solve(m)\n",
    "    return getvalue(β)\n",
    "end\n",
    "\n",
    "##### ridge linear regression #####\n",
    "function ridgelinear(X, y, ρ)\n",
    "    # OutputFlag=0 to hide output from solver\n",
    "    m = Model(solver=GurobiSolver(OutputFlag=0))\n",
    "    \n",
    "    p = size(X, 2) #nb of columns\n",
    "\n",
    "    # Variables\n",
    "    @variable(m, t)\n",
    "    @variable(m, u)\n",
    "    @variable(m, β[1:p])\n",
    "    \n",
    "    # Constraints\n",
    "    @constraint(m, norm(y - X * β) <= t)\n",
    "    @constraint(m, norm(β) <= u)\n",
    "\n",
    "    # Objective\n",
    "    @objective(m, Min, t + ρ * u)\n",
    "\n",
    "    solve(m)\n",
    "    return getvalue(β)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findBestRho (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function findBestRho(train_X,\n",
    "                    train_y,\n",
    "                    val_X,\n",
    "                    val_y, \n",
    "                    rho_list)\n",
    "    p = size(train_X, 2)\n",
    "    k = length(rho_list)\n",
    "    #instantiate arrays\n",
    "    β_lasso_list = zeros(k, p)\n",
    "    β_ridge_list = zeros(k, p)\n",
    "    lasso_scores = zeros(k)\n",
    "    ridge_scores = zeros(k)\n",
    "    \n",
    "    for i in 1:length(rho_list)\n",
    "        # training on train sets for both regression methods\n",
    "        \n",
    "        β_lasso_list[i, :] = lassolinear(train_X, train_y, rho_list[i])\n",
    "        #println(\"\\nβ_lasso for rho =\", rho_list[i], β_lasso_list[i, :])\n",
    "        β_ridge_list[i, :] = ridgelinear(train_X, train_y, rho_list[i])\n",
    "        #println(\"\\nβ_ridge for rho =\", rho_list[i], β_ridge_list[i, :])\n",
    "        \n",
    "        # performance metrics on validation sets for both regression methods\n",
    "        lasso_scores[i] = norm(val_y - val_X * β_lasso_list[i, :])\n",
    "        ridge_scores[i] = norm(val_y - val_X * β_ridge_list[i, :])\n",
    "        \n",
    "        \n",
    "    end\n",
    "    #println(lasso_scores)\n",
    "    #println(ridge_scores)\n",
    "    argmin_lasso = indmin(lasso_scores)\n",
    "    argmin_ridge = indmin(ridge_scores)\n",
    "    \n",
    "    return rho_list[argmin_lasso], rho_list[argmin_ridge]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Best rho for lasso: 0.1\n",
      "Best rho for ridge: 2.0\n"
     ]
    }
   ],
   "source": [
    "rho_list = [0.001, 0.01, 0.1, 1, 2]\n",
    "\n",
    "best_rho = findBestRho(train_X, train_y, val_X, val_y, rho_list)\n",
    "\n",
    "println(\"Best rho for lasso: \", best_rho[1] )\n",
    "println(\"Best rho for ridge: \", best_rho[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "\n",
      "Best β for standard linear regression is: [-0.182837, 0.0463545, 0.0566232, 0.814289, -5.54437, 6.49243, -0.00690827, -1.03113, 0.541436, -0.0123992, -0.524355, 0.0130461, -0.394916]\n",
      "Academic license - for non-commercial use only\n",
      "\n",
      "Best β for lasso is: [-0.152615, 0.0472997, 0.0245548, 0.525413, -0.0077624, 6.19149, -0.0105729, -0.985242, 0.534167, -0.0141383, -0.50909, 0.0131665, -0.428667]\n",
      "Academic license - for non-commercial use only\n",
      "\n",
      "Best β for ridge is: [-0.119194, 0.0540906, 0.0293727, 0.521321, -0.0163899, 5.33832, 0.00387411, -0.923509, 0.49436, -0.0129209, -0.448035, 0.0225441, -0.500597]\n"
     ]
    }
   ],
   "source": [
    "# retrain the whole model with training and validation sets together\n",
    "\n",
    "new_train_X = vcat(train_X, val_X)\n",
    "new_train_y = vcat(train_y, val_y)\n",
    "\n",
    "# find best beta for standard linear regression\n",
    "β_standard = standardlinear(new_train_X, new_train_y)\n",
    "println(\"\\nBest β for standard linear regression is: \", β_standard)\n",
    "\n",
    "# find best beta for lasso\n",
    "\n",
    "ρ_lasso = best_rho[1]\n",
    "β_lasso = lassolinear(new_train_X, new_train_y, ρ_lasso)\n",
    "println(\"\\nBest β for lasso is: \", β_lasso)\n",
    "\n",
    "# find best beta for ridge\n",
    "\n",
    "ρ_ridge = best_rho[2]\n",
    "β_ridge = ridgelinear(new_train_X, new_train_y, ρ_ridge)\n",
    "println(\"\\nBest β for ridge is: \", β_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard linear regression score: 91.31777137966286\n",
      "Lasso score: 89.47021659084704\n",
      "Ridge score: 83.59529327926523\n",
      "Baseline score: 129.2265350398843\n",
      "\n",
      "Relative gap standard linear regression % baseline: 29.335123508899578 %\n",
      "Relative gap lasso % baseline: 30.764825843830703 %\n",
      "Relative gap ridge % baseline: 35.3110464089558 %\n"
     ]
    }
   ],
   "source": [
    "# score standard linear regression\n",
    "score_standard = norm(test_y - test_X * β_standard)\n",
    "println(\"Standard linear regression score: \", score_standard)\n",
    "\n",
    "# score lasso\n",
    "score_lasso = norm(test_y - test_X * β_lasso)\n",
    "println(\"Lasso score: \", score_lasso)\n",
    "\n",
    "# score ridge\n",
    "score_ridge = norm(test_y - test_X * β_ridge)\n",
    "println(\"Ridge score: \", score_ridge)\n",
    "\n",
    "# baseline\n",
    "train_y_mean = mean(new_train_y) #use mean on training and validation sets\n",
    "score_baseline = norm(test_y - train_y_mean)\n",
    "println(\"Baseline score: \", score_baseline)\n",
    "\n",
    "# compare scores of regression with the baseline model\n",
    "println(\"\\nRelative gap standard linear regression % baseline: \", (score_baseline - score_standard)*100/score_baseline, \" %\" )\n",
    "println(\"Relative gap lasso % baseline: \", (score_baseline - score_lasso)*100/score_baseline, \" %\" )\n",
    "println(\"Relative gap ridge % baseline: \", (score_baseline - score_ridge)*100/score_baseline, \" %\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.095. Homework 4\n",
    "\n",
    "Kim-Anh-Nhi Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "items = pd.read_csv(\"items.csv\")\n",
    "sales = pd.read_csv(\"sales.csv\")\n",
    "info = pd.read_csv(\"sideinformation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we look at what the 3 tables look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>ondisplay</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>103665</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>105574</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>105575</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>105577</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>105737</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  item_nbr  ondisplay  onpromotion  unit_sales\n",
       "0  2017-01-02    103665      False        False         0.0\n",
       "1  2017-01-02    105574      False        False         0.0\n",
       "2  2017-01-02    105575       True        False         3.0\n",
       "3  2017-01-02    105577       True        False         1.0\n",
       "4  2017-01-02    105737       True        False         1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# check there are 100 unique items\n",
    "print(sales['item_nbr'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>cost</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103665</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105574</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105575</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105577</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105737</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1044</td>\n",
       "      <td>0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_nbr        family  class  perishable  cost  price\n",
       "0    103665  BREAD/BAKERY   2712           1  0.72   4.00\n",
       "1    105574     GROCERY I   1045           0  1.97   3.33\n",
       "2    105575     GROCERY I   1045           0  1.02   3.72\n",
       "3    105577     GROCERY I   1045           0  2.21   4.89\n",
       "4    105737     GROCERY I   1044           0  2.35   3.71"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "12\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "# check how many unique items, families and classes\n",
    "print(items['item_nbr'].unique().size)\n",
    "print(items['family'].unique().size)\n",
    "print(items['class'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>isHoliday</th>\n",
       "      <th>oilPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>True</td>\n",
       "      <td>52.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>False</td>\n",
       "      <td>53.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>53.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>False</td>\n",
       "      <td>53.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>False</td>\n",
       "      <td>52.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  isHoliday  oilPrice\n",
       "0  2017-01-02       True     52.36\n",
       "1  2017-01-03      False     53.26\n",
       "2  2017-01-04      False     53.06\n",
       "3  2017-01-05      False     53.62\n",
       "4  2017-01-06      False     52.41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We encode the categorical variables as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder for item_nbr, family and class\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(list(items['item_nbr'].unique()))\n",
    "items['item_nbr_encoded'] = le1.transform(items['item_nbr'])\n",
    "\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(list(items['family'].unique()))\n",
    "items['family_encoded'] = le2.transform(items['family'])\n",
    "\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "le3.fit(list(items['class'].unique()))\n",
    "items['class_encoded'] = le3.transform(items['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can merge the 3 tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge items and sales, sales on the left\n",
    "df = pd.merge(sales, items, on = 'item_nbr', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with info table\n",
    "df = pd.merge(df, info, on = 'date', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Data Processing: \n",
    "1. We create 3 columns to take the date into account\n",
    "2. We round the sales as integers, because there is numerical float issues for some rows (e.g. 3.999999998 instead of 4.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column year, month, day\n",
    "df['year'] = df['date'].str[0:4]\n",
    "df['month'] = df['date'].str[5:7]\n",
    "df['day'] = df['date'].str[8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unit_sales'] = round(df['unit_sales'], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We export the final merged table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_data_with_date.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We separate the data into a train and a test set\n",
    "- The training set contains all the observations from 2017-01-02 to 2017-08-14\n",
    "- The testing set contains all the observations from our target date only, i.e., 2017-08-15\n",
    "- the target variable for each set (the y variable) is the `sales` column\n",
    "- Finally, we export the different tables, so we can use them for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500 100\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = df.loc[df['date'] != '2017-08-15'], df.loc[df['date'] == '2017-08-15']\n",
    "print(len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_train = df_train.drop(['item_nbr', 'family', 'class', 'date', 'unit_sales'], axis = 1)\n",
    "df2_test = df_test.drop([ 'item_nbr', 'family', 'class', 'date', 'unit_sales'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = df_train[['unit_sales']], df_test[['unit_sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_train.to_csv(\"X_train.csv\")\n",
    "df2_test.to_csv(\"X_test.csv\")\n",
    "y_train.to_csv(\"y_train.csv\")\n",
    "y_test.to_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (b) Model training: Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"final_data_with_date.csv\")\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "\n",
    "# we drop the 'Unnamed: 0' column (old rows in the original tables)\n",
    "X_train = X_train.drop(['Unnamed: 0'], axis = 1)\n",
    "X_test = X_test.drop(['Unnamed: 0'], axis = 1)\n",
    "y_train = y_train.drop(['Unnamed: 0'], axis = 1)\n",
    "y_test = y_test.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "def savemodel(filename, model):\n",
    "    # Save to file in the current working directory\n",
    "    path = filename + \".joblib\"\n",
    "    joblib_file = path\n",
    "    joblib.dump(model, joblib_file)\n",
    "\n",
    "def loadmodel(joblib_file):\n",
    "    # Load from file\n",
    "    joblib_model = joblib.load(joblib_file)\n",
    "    return(joblib_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters that we are going to tune\n",
    "DT_param_grid = { 'max_depth':[2, 3, 4, 5, 10, 20, 50],\n",
    "                'min_samples_split': [2, 10, 50, 100],\n",
    "                 'min_samples_leaf': [1, 5, 10]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 84 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=16)]: Done  40 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=16)]: Done  53 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=16)]: Done  66 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=16)]: Done  81 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=16)]: Done  96 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=16)]: Done 113 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=16)]: Done 130 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=16)]: Done 149 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=16)]: Done 189 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=16)]: Done 210 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=16)]: Done 233 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=16)]: Done 256 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=16)]: Done 281 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=16)]: Done 306 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=16)]: Done 333 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=16)]: Done 389 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=16)]: Done 449 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=16)]: Done 480 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=16)]: Done 513 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=16)]: Done 546 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=16)]: Done 581 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=16)]: Done 616 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=16)]: Done 653 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=16)]: Done 690 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=16)]: Done 729 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=16)]: Done 809 tasks      | elapsed:   45.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=20, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=10,\n",
      "           min_samples_split=100, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 840 out of 840 | elapsed:   46.7s finished\n"
     ]
    }
   ],
   "source": [
    "DT = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid = DT_param_grid, \n",
    "                              scoring='neg_mean_absolute_error', \n",
    "                              cv=10, \n",
    "                              verbose=10, n_jobs = 16)\n",
    "DT.fit(X_train, y_train)\n",
    "DTbest = DT.best_estimator_\n",
    "print(DTbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "savemodel(\"DT\", DTbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Model performance, let's compare with a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE with rounded predictions: 1.49\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "ypred = pd.DataFrame(DTbest.predict(X_test))\n",
    "\n",
    "# but sales volumes are integers so, we round each prediction to the closest integer\n",
    "ypred_round = round(ypred)\n",
    "\n",
    "# get the MAE\n",
    "MAE = mean_absolute_error(y_test, ypred_round)\n",
    "\n",
    "print('MAE with rounded predictions:', MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model predicts that sales for August 15 are exactly the sales from the previous day \n",
    "y_baseline = y_train.iloc[-100:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of baseline:  1.94\n"
     ]
    }
   ],
   "source": [
    "# get the MAE\n",
    "MAE_b = mean_absolute_error(y_test, y_baseline)\n",
    "print(\"MAE of baseline: \", MAE_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data for the optimization problem\n",
    "We will switch to Julia in order to solve the optimization problem.\n",
    "\n",
    "To do so, we will need the values `y_train`, `y_pred`, `y_baseline`, as well as the leaves in the decision tree we built that correspond to each value y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions y hat:\n",
    "ypred_round.to_csv(\"y_pred.csv\")\n",
    "y_baseline.to_csv(\"y_baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform boolean into integers\n",
    "X_test[\"ondisplay\"] = X_test[\"ondisplay\"].astype('int64')\n",
    "X_test[\"onpromotion\"] = X_test[\"onpromotion\"].astype('int64')\n",
    "X_test[\"isHoliday\"] = X_test[\"isHoliday\"].astype('int64')\n",
    "X_test.to_csv(\"X_test_int.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utilisateur\\.julia\\v0.6\\Conda\\deps\\usr\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\utilisateur\\.julia\\v0.6\\Conda\\deps\\usr\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\utilisateur\\.julia\\v0.6\\Conda\\deps\\usr\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# export the baseline data for the optimization model in Julia\n",
    "X_baseline = X_train.iloc[-100:, :]\n",
    "# transform boolean into integers\n",
    "X_baseline[\"ondisplay\"] = X_baseline[\"ondisplay\"].astype('int64')\n",
    "X_baseline[\"onpromotion\"] = X_baseline[\"onpromotion\"].astype('int64')\n",
    "X_baseline[\"isHoliday\"] = X_baseline[\"isHoliday\"].astype('int64')\n",
    "X_baseline.to_csv(\"X_baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the leaf' number where each observation belongs\n",
    "leaf_belong_train = DTbest.apply(X_train)\n",
    "leaf_belong_test = DTbest.apply(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out the leaves for both data sets: each row is a pair of {unit_sales, leaf where the corresponding observation was}\n",
    "\n",
    "train_leaves = []\n",
    "for i in range(len(y_train)):\n",
    "     train_leaves.append((list(y_train['unit_sales'])[i], leaf_belong_train[i]))\n",
    "        \n",
    "test_leaves = []\n",
    "for i in range(len(y_test)):\n",
    "     test_leaves.append((list(y_test['unit_sales'])[i], leaf_belong_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the leaves \n",
    "train_leaves = np.array(train_leaves)\n",
    "np.savetxt(\"train_leaves.csv\", train_leaves, delimiter=\",\")\n",
    "\n",
    "test_leaves = np.array(test_leaves)\n",
    "np.savetxt(\"test_leaves.csv\", test_leaves, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get all unit_sales values belonging to a leaf\n",
    "\n",
    "def fetch_points_in_leaf(leaf, train_leaves):\n",
    "    n = len(train_leaves)\n",
    "    in_leaf = []\n",
    "    for x in train_leaves:\n",
    "        if x[1] == leaf:\n",
    "            in_leaf.append(x[0])\n",
    "    return(in_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the purpose to get a matrix where every row has the same length\n",
    "# we add -1 to complete the rows\n",
    "def complete_list(l, length):\n",
    "    if len(l) < length:\n",
    "        new_list = [-1 for i in range(length)]\n",
    "        for i in range(len(l)):\n",
    "            new_list[i] = l[i]\n",
    "    return(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives the unit_sales from the training set which are in a particular leaf\n",
    "def get_leaf_points(train_leaves, test_leaves):\n",
    "    test_leaf_data = []\n",
    "    for x in test_leaves:\n",
    "        leaf = x[1] # leaf where y_pred[i] belongs\n",
    "        in_leaf = fetch_points_in_leaf(leaf, train_leaves)\n",
    "        test_leaf_data.append( complete_list(in_leaf, len(train_leaves)) )     \n",
    "    return(test_leaf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weights corresponding to a leaf\n",
    "# equals to 1/(number of points in the leaf)\n",
    "\n",
    "def get_weight(train_leaves, test_leaves):\n",
    "    weights = []\n",
    "    leaf_points = get_leaf_points(train_leaves, test_leaves)\n",
    "    for x in leaf_points:\n",
    "        count = 0\n",
    "        for i in range(len(x)):\n",
    "            if x[i] != -1:\n",
    "                count +=1\n",
    "        weights.append(1/count)\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_leaf_data = get_leaf_points(train_leaves, test_leaves)\n",
    "weights = get_weight(train_leaves, test_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the leaves data\n",
    "\n",
    "test_leaf_data = np.array(test_leaf_data)\n",
    "test_leaf_data = np.transpose(test_leaf_data) # transpose because otherwise, the csv will have 22500 columns VS 100 columns\n",
    "np.savetxt(\"test_leaf_data_T.csv\", test_leaf_data, delimiter=\",\")\n",
    "weights = np.array(weights)\n",
    "np.savetxt(\"weights.csv\", weights, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
